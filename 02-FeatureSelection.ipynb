{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msng    # normally this is imported under the alias 'msno'\n",
    "                            # but this is the name of the user id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.append('/Users/kendra/data_science/Projects/sharedCode')\n",
    "\n",
    "import util as u\n",
    "import assess_clf_models as acm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = u.open_pkl('Data/X_train.pkl')\n",
    "df = u.open_pkl('Data/user_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added these to previous data processing script after first time through:\n",
    "if 1 == 0:\n",
    "    df.rename(columns={'total_secs_count':'num_log_entries'}, inplace=True)\n",
    "\n",
    "    df['time_since_registration'] = round((dt.datetime(year=2017, month=4, day=30) - df['registration_init_time']) \n",
    "                                     / dt.timedelta(days=30), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['registered_via'] = df['registered_via'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['time_since_registration'].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msng.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msng.bar(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msng.heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.dropna())/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['trans_count'].dropna())/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing data:\n",
    "- At the least, need to keep transaction data\n",
    "- At the worst, drop all na's and retain 75% of data\n",
    "**For now: drop all na's**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df.dropna()\n",
    "df_drop.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_drop.corr()\n",
    "\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr, vmin=-1, vmax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- num_100, num_unq, total num songs (mean & sum), total_secs sum\n",
    "    - compute PCA\n",
    "- short_pct & full_pct (inverse)\n",
    "    - keep short_pct\n",
    "    - drop num_25 thru num_985"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - song features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_songs = PCA(n_components=1)\n",
    "df_songs_pca = df_drop[['num_100_mean', 'num_unq_mean', 'num_songs_mean', 'num_songs_sum',\n",
    "       'total_secs_mean', 'total_secs_sum']]\n",
    "songs_pca = pca_songs.fit_transform(df_songs_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(songs_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_cols = ['payment_plan_days_mode', 'payment_plan_days_sum',\n",
    "       'plan_list_price_mode', 'plan_list_price_sum',\n",
    "       'actual_amount_paid_mode', 'actual_amount_paid_sum',\n",
    "        'plan_actual_diff_abs_max', 'plan_actual_diff_mode',\n",
    "       'is_auto_renew_mode', 'is_auto_renew_sum', 'is_cancel_mode',\n",
    "       'is_cancel_sum', 'trans_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr.loc[trans_cols, trans_cols], vmin=-1, vmax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- transaction features:\n",
    "    - PCA on payment_plan_days mode or sum, plan_list_price sum or mode or actual sum or mode\n",
    "    - one of plan_actual_diff abs_max of mode\n",
    "    - keep is_auto_renew mode, drop sum\n",
    "    - keep is_cancel_mode, drop sum\n",
    "    - keep trans_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_trans = PCA(n_components=1)\n",
    "df_trans_pca = df_drop[['payment_plan_days_mode', 'payment_plan_days_sum',\n",
    "       'plan_list_price_mode', 'plan_list_price_sum',\n",
    "       'actual_amount_paid_mode', 'actual_amount_paid_sum']]\n",
    "trans_pca = pca_songs.fit_transform(df_trans_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(trans_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_cols_1 = ['registered_via', \n",
    "             'short_pct_mean', \n",
    "             'payment_method_most_common_mode',\n",
    "             'plan_actual_diff_abs_max',\n",
    "             'is_auto_renew_mode', 'is_cancel_mode',\n",
    "             'trans_count', \n",
    "             'time_since_registration']\n",
    "\n",
    "df_feat1 = df_drop[fs_cols_1]\n",
    "df_feat1 = df_feat1.join(pd.DataFrame(songs_pca, columns=['song_pca']))\n",
    "df_feat1 = df_feat1.join(pd.DataFrame(trans_pca, columns=['transactions_pca']))\n",
    "\n",
    "df_feat1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_cols_2 = fs_cols_1 + ['num_songs_mean', 'actual_amount_paid_mode']\n",
    "df_feat2 = df_drop[fs_cols_2]\n",
    "\n",
    "df_feat2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline / Pre-processing\n",
    "- normalize numerical categories\n",
    "- encode categorial\n",
    "- leave Boolean (1/0) as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical features are in same positions in feature set 1 & 2, so only need to define one list & preprocessor\n",
    "feat_num = ['short_pct_mean', \n",
    "             'plan_actual_diff_abs_max', \n",
    "             'trans_count', \n",
    "             'time_since_registration', \n",
    "             'song_pca', # num_songs_mean in feature set 2\n",
    "             'transactions_pca'] # 'actual_amount_paid_mode' in feature set 2\n",
    "\n",
    "# define this list for feature names\n",
    "feat2_num = ['short_pct_mean', \n",
    "             'plan_actual_diff_abs_max', \n",
    "             'trans_count', \n",
    "             'time_since_registration', \n",
    "             'num_songs_mean',\n",
    "             'actual_amount_paid_mode']\n",
    "\n",
    "feat_num_idx = [list(df_feat1.columns).index(x) for x in feat_num]\n",
    "\n",
    "# define Scaling preprocessor\n",
    "preproc_scale = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), feat_num_idx)\n",
    "])\n",
    "\n",
    "# for models that don't require scaling, we want to pass-through these features:\n",
    "preproc_num_pass = ColumnTransformer(transformers=[\n",
    "    ('num', 'passthrough', feat_num_idx)\n",
    "])\n",
    "\n",
    "# feature names = feat_num or feat2_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reg_via_3', 'reg_via_4', 'reg_via_7', 'reg_via_9', 'reg_via_13']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def fix_ohe_names(x):\n",
    "    s = re.sub('x0', 'reg_via', x)\n",
    "    s = re.sub('.0', '', s)\n",
    "    return s\n",
    "\n",
    "cat_cols = ['registered_via']\n",
    "cat_cols_idx = [list(df_feat1.columns).index(x) for x in cat_cols]\n",
    "\n",
    "preproc_ohe = ColumnTransformer(transformers=[('cat', OneHotEncoder(categories='auto'), cat_cols_idx)])\n",
    "\n",
    "# fit to get feature names\n",
    "preproc_ohe.fit(df_feat1)\n",
    "feat_ohe = preproc_ohe.named_transformers_['cat'].get_feature_names()\n",
    "feat_ohe = feat_ohe.tolist()\n",
    "\n",
    "feat_ohe = list(map(fix_ohe_names, feat_ohe))\n",
    "feat_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_cols = ['payment_method_most_common_mode', 'is_auto_renew_mode', 'is_cancel_mode']\n",
    "pass_cols_idx = [list(df_feat1.columns).index(x) for x in pass_cols]\n",
    "\n",
    "preproc_pass = ColumnTransformer(transformers=[\n",
    "        ('as_is', 'passthrough', pass_cols_idx), \n",
    "])\n",
    "\n",
    "# feature names = pass_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sewing them together\n",
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_with_scale = Pipeline([\n",
    "    ('all', FeatureUnion([\n",
    "        ('ohe', preproc_ohe),\n",
    "        ('num', preproc_scale),\n",
    "        ('pass', preproc_pass)\n",
    "    ])\n",
    "    )\n",
    "])\n",
    "\n",
    "feat_names1 = feat_ohe + feat_num + pass_cols\n",
    "feat_names2 = feat_ohe + feat2_num + pass_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling not needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_no_scale = Pipeline([\n",
    "    ('all', FeatureUnion([\n",
    "        ('ohe', preproc_ohe),\n",
    "        ('num', preproc_num_pass),\n",
    "        ('pass', preproc_pass)\n",
    "    ])\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- CatBoost will not require any pre-processing. Will simply need to feed in the categorical columns (index 0)\n",
    "- can also try feeding in data without pre-processing into tree-based models\n",
    "    - see: https://towardsdatascience.com/one-hot-encoding-is-making-your-tree-based-ensembles-worse-heres-why-d64b282b5769"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX1_scale = pipe_with_scale.fit_transform(df_feat1)\n",
    "test_data = trX1_scale.todense()[0].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX1 = pipe_no_scale.fit_transform(df_feat1)\n",
    "test_data_no_scale = trX1.todense()[0].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not scaled</th>\n",
       "      <th>scaled</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reg_via_3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_via_4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_via_7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_via_9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_via_13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_pct_mean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.282839</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plan_actual_diff_abs_max</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.036292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.228602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_since_registration</th>\n",
       "      <td>40.800000</td>\n",
       "      <td>-0.122216</td>\n",
       "      <td>40.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_pca</th>\n",
       "      <td>-134821.246306</td>\n",
       "      <td>-0.731279</td>\n",
       "      <td>-134821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions_pca</th>\n",
       "      <td>32.481059</td>\n",
       "      <td>0.102439</td>\n",
       "      <td>32.4811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_method_most_common_mode</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_auto_renew_mode</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_cancel_mode</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    not scaled    scaled        0\n",
       "reg_via_3                             1.000000  1.000000      NaN\n",
       "reg_via_4                             0.000000  0.000000      NaN\n",
       "reg_via_7                             0.000000  0.000000      NaN\n",
       "reg_via_9                             0.000000  0.000000      NaN\n",
       "reg_via_13                            0.000000  0.000000      NaN\n",
       "short_pct_mean                        0.000000 -1.282839        0\n",
       "plan_actual_diff_abs_max              0.000000 -0.036292        0\n",
       "trans_count                           1.000000 -0.228602        1\n",
       "time_since_registration              40.800000 -0.122216     40.8\n",
       "song_pca                        -134821.246306 -0.731279  -134821\n",
       "transactions_pca                     32.481059  0.102439  32.4811\n",
       "payment_method_most_common_mode       0.000000  0.000000        0\n",
       "is_auto_renew_mode                    0.000000  0.000000        0\n",
       "is_cancel_mode                        0.000000  0.000000        0"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame({'not scaled':test_data_no_scale, \n",
    "             'scaled':test_data},\n",
    "            index=feat_names1)\n",
    "\n",
    "test_df.join(df_feat1.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "Competition submissions were evaluated by log-loss, so include it in our metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver='liblinear')\n",
    "rand_for = RandomForestClassifier(n_estimators=10)\n",
    "grad_boost = GradientBoostingClassifier()\n",
    "cb = CatBoostClassifier(cat_features=cat_cols_idx, logging_level='Silent')\n",
    "dtb = BaggingClassifier(base_estimator=DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_drop['is_churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware our dataset is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_feat1_log_reg = acm.assess_model_2(pipe_with_scale, log_reg, df_feat1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_feat2_log_reg = acm.assess_model_2(pipe_with_scale, log_reg, df_feat2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision-0                    0.957912\n",
       "Recall-0 (Specificty)          0.993849\n",
       "F1score-0                      0.975550\n",
       "Precision-1                    0.802278\n",
       "Recall-1 (Sensitivity)         0.363668\n",
       "F1score-1                      0.500460\n",
       "TN                        134986.200000\n",
       "FN                          5931.000000\n",
       "FP                           835.400000\n",
       "TP                          3389.600000\n",
       "AUC                            0.920155\n",
       "Accuracy                       0.953381\n",
       "LogLoss                        1.610172\n",
       "dtype: float64"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_feat1_log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision-0                    0.957619\n",
       "Recall-0 (Specificty)          0.993596\n",
       "F1score-0                      0.975276\n",
       "Precision-1                    0.793785\n",
       "Recall-1 (Sensitivity)         0.359204\n",
       "F1score-1                      0.494578\n",
       "TN                        134951.800000\n",
       "FN                          5972.600000\n",
       "FP                           869.800000\n",
       "TP                          3348.000000\n",
       "AUC                            0.922288\n",
       "Accuracy                       0.952857\n",
       "LogLoss                        1.628257\n",
       "dtype: float64"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_feat2_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two feature sets (1 = with PCA, 2 = selected un-transformed features) perform similarly in a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_results_rf = acm.assess_model_2(pipe_no_scale, rand_for, df_feat1, y)\n",
    "mini_results_gb = acm.assess_model_2(pipe_no_scale, grad_boost, df_feat1, y)\n",
    "mini_results_dtb = acm.assess_model_2(pipe_no_scale, dtb, df_feat1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision-0                    0.971632\n",
       "Recall-0 (Specificty)          0.992615\n",
       "F1score-0                      0.982012\n",
       "Precision-1                    0.842953\n",
       "Recall-1 (Sensitivity)         0.577688\n",
       "F1score-1                      0.685538\n",
       "TN                        134818.600000\n",
       "FN                          3936.200000\n",
       "FP                          1003.000000\n",
       "TP                          5384.400000\n",
       "AUC                            0.895119\n",
       "Accuracy                       0.965970\n",
       "LogLoss                        1.175363\n",
       "dtype: float64"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_results_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision-0                    0.971828\n",
       "Recall-0 (Specificty)          0.993936\n",
       "F1score-0                      0.982758\n",
       "Precision-1                    0.867863\n",
       "Recall-1 (Sensitivity)         0.580135\n",
       "F1score-1                      0.695388\n",
       "TN                        134998.000000\n",
       "FN                          3913.400000\n",
       "FP                           823.600000\n",
       "TP                          5407.200000\n",
       "AUC                            0.949705\n",
       "Accuracy                       0.967363\n",
       "LogLoss                        1.127245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_results_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision-0                    0.971662\n",
       "Recall-0 (Specificty)          0.992546\n",
       "F1score-0                      0.981993\n",
       "Precision-1                    0.841843\n",
       "Recall-1 (Sensitivity)         0.578182\n",
       "F1score-1                      0.685524\n",
       "TN                        134809.200000\n",
       "FN                          3931.600000\n",
       "FP                          1012.400000\n",
       "TP                          5389.000000\n",
       "AUC                            0.896821\n",
       "Accuracy                       0.965937\n",
       "LogLoss                        1.176505\n",
       "dtype: float64"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_results_dtb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_results_cb = acm.assess_model_only(cb, df_feat1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision-0</th>\n",
       "      <th>Recall-0 (Specificty)</th>\n",
       "      <th>F1score-0</th>\n",
       "      <th>Precision-1</th>\n",
       "      <th>Recall-1 (Sensitivity)</th>\n",
       "      <th>F1score-1</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TP</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.957912</td>\n",
       "      <td>0.993849</td>\n",
       "      <td>0.975550</td>\n",
       "      <td>0.802278</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>0.500460</td>\n",
       "      <td>134986.2</td>\n",
       "      <td>5931.0</td>\n",
       "      <td>835.4</td>\n",
       "      <td>3389.6</td>\n",
       "      <td>0.920155</td>\n",
       "      <td>0.953381</td>\n",
       "      <td>1.610172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg-FS2</th>\n",
       "      <td>0.957619</td>\n",
       "      <td>0.993596</td>\n",
       "      <td>0.975276</td>\n",
       "      <td>0.793785</td>\n",
       "      <td>0.359204</td>\n",
       "      <td>0.494578</td>\n",
       "      <td>134951.8</td>\n",
       "      <td>5972.6</td>\n",
       "      <td>869.8</td>\n",
       "      <td>3348.0</td>\n",
       "      <td>0.922288</td>\n",
       "      <td>0.952857</td>\n",
       "      <td>1.628257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandFor</th>\n",
       "      <td>0.971632</td>\n",
       "      <td>0.992615</td>\n",
       "      <td>0.982012</td>\n",
       "      <td>0.842953</td>\n",
       "      <td>0.577688</td>\n",
       "      <td>0.685538</td>\n",
       "      <td>134818.6</td>\n",
       "      <td>3936.2</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>5384.4</td>\n",
       "      <td>0.895119</td>\n",
       "      <td>0.965970</td>\n",
       "      <td>1.175363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradBst</th>\n",
       "      <td>0.971828</td>\n",
       "      <td>0.993936</td>\n",
       "      <td>0.982758</td>\n",
       "      <td>0.867863</td>\n",
       "      <td>0.580135</td>\n",
       "      <td>0.695388</td>\n",
       "      <td>134998.0</td>\n",
       "      <td>3913.4</td>\n",
       "      <td>823.6</td>\n",
       "      <td>5407.2</td>\n",
       "      <td>0.949705</td>\n",
       "      <td>0.967363</td>\n",
       "      <td>1.127245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagged-DecTr</th>\n",
       "      <td>0.971662</td>\n",
       "      <td>0.992546</td>\n",
       "      <td>0.981993</td>\n",
       "      <td>0.841843</td>\n",
       "      <td>0.578182</td>\n",
       "      <td>0.685524</td>\n",
       "      <td>134809.2</td>\n",
       "      <td>3931.6</td>\n",
       "      <td>1012.4</td>\n",
       "      <td>5389.0</td>\n",
       "      <td>0.896821</td>\n",
       "      <td>0.965937</td>\n",
       "      <td>1.176505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat Boost</th>\n",
       "      <td>0.972699</td>\n",
       "      <td>0.994085</td>\n",
       "      <td>0.983276</td>\n",
       "      <td>0.873170</td>\n",
       "      <td>0.593417</td>\n",
       "      <td>0.706603</td>\n",
       "      <td>135018.2</td>\n",
       "      <td>3789.6</td>\n",
       "      <td>803.4</td>\n",
       "      <td>5531.0</td>\n",
       "      <td>0.954258</td>\n",
       "      <td>0.968355</td>\n",
       "      <td>1.092978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Precision-0  Recall-0 (Specificty)  F1score-0  Precision-1  \\\n",
       "LogReg           0.957912               0.993849   0.975550     0.802278   \n",
       "LogReg-FS2       0.957619               0.993596   0.975276     0.793785   \n",
       "RandFor          0.971632               0.992615   0.982012     0.842953   \n",
       "GradBst          0.971828               0.993936   0.982758     0.867863   \n",
       "Bagged-DecTr     0.971662               0.992546   0.981993     0.841843   \n",
       "Cat Boost        0.972699               0.994085   0.983276     0.873170   \n",
       "\n",
       "              Recall-1 (Sensitivity)  F1score-1        TN      FN      FP  \\\n",
       "LogReg                      0.363668   0.500460  134986.2  5931.0   835.4   \n",
       "LogReg-FS2                  0.359204   0.494578  134951.8  5972.6   869.8   \n",
       "RandFor                     0.577688   0.685538  134818.6  3936.2  1003.0   \n",
       "GradBst                     0.580135   0.695388  134998.0  3913.4   823.6   \n",
       "Bagged-DecTr                0.578182   0.685524  134809.2  3931.6  1012.4   \n",
       "Cat Boost                   0.593417   0.706603  135018.2  3789.6   803.4   \n",
       "\n",
       "                  TP       AUC  Accuracy   LogLoss  \n",
       "LogReg        3389.6  0.920155  0.953381  1.610172  \n",
       "LogReg-FS2    3348.0  0.922288  0.952857  1.628257  \n",
       "RandFor       5384.4  0.895119  0.965970  1.175363  \n",
       "GradBst       5407.2  0.949705  0.967363  1.127245  \n",
       "Bagged-DecTr  5389.0  0.896821  0.965937  1.176505  \n",
       "Cat Boost     5531.0  0.954258  0.968355  1.092978  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_df = pd.DataFrame([fit_feat1_log_reg, fit_feat2_log_reg, mini_results_rf, mini_results_gb, mini_results_dtb, \n",
    "                        mini_results_cb],\n",
    "             index=['LogReg','LogReg-FS2','RandFor','GradBst','Bagged-DecTr', 'Cat Boost'])\n",
    "comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
